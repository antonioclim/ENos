# LLM-Aware Exercises: Text Processing
## Critical Evaluation Exercises for AI Results

> Laboratory observation: if you use an LLM, treat it as a colleague who explains, not as an autopilot. Ask it to justify the steps, then validate with a minimal command (`--help`, `man`, a small test). In the lab you can immediately see the difference between "I understood" and "I pasted".
> Operating Systems | Bucharest University of Economic Studies - CSIE  
> Seminar 4 | LLM-Integrated Learning  
> Purpose: Developing critical thinking in the AI era

---

## Why LLM-Aware Exercises?

### The Current Context

In 2025, students have access to LLMs (ChatGPT, Claude, Gemini) that can generate code. This is a reality that education must embrace, not ignore.

### Objectives

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¯ LLM-AWARE OBJECTIVES                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  1. CRITICAL EVALUATION                                                 â”‚
â”‚     Students learn to verify, not to accept blindly                    â”‚
â”‚                                                                         â”‚
â”‚  2. DEBUGGING AI OUTPUT                                                 â”‚
â”‚     Identifying and correcting errors in generated code                â”‚
â”‚                                                                         â”‚
â”‚  3. OPTIMISATION                                                        â”‚
â”‚     Improving generated solutions                                       â”‚
â”‚                                                                         â”‚
â”‚  4. DEEP UNDERSTANDING                                                  â”‚
â”‚     You cannot evaluate what you do not understand                     â”‚
â”‚                                                                         â”‚
â”‚  5. PROMPT ENGINEERING                                                  â”‚
â”‚     Formulating clear requirements for better results                  â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Philosophy

> "The LLM is a tool, not a replacement. A poor mechanic with good tools still remains a poor mechanic."

---

## General Instructions

For each exercise:

1. You receive an output generated by an LLM (real or simulated)
2. You analyse correctness and quality
3. You test on the provided data
4. You identify problems (if any exist)
5. You improve the solution

---

# EXERCISE 1: REGEX VALIDATION

> *Observation from experience: students who test the regex in regex101.com before putting it in a script have 3-4 times fewer errors. Take an extra 30 seconds for verification â€” it is worth it.*

## Context
A student asked an LLM: "Generate a regex for email validation in bash with grep"

## LLM Output (Simulated)

```bash
# Regex for email generated by AI:
grep -E "^[a-zA-Z0-9]+@[a-zA-Z]+\.[a-zA-Z]+$" emails.txt
```

## Test Data

```bash
# Create the test file
cat > test_emails.txt << 'EOF'
john.doe@example.com
invalid-email
user@domain.co.uk
alice_wonder@gmail.com
test@test
user.name+tag@domain.org
@nodomain.com
noat.com
simple@test.io
123@numbers.com
EOF
```

## Tasks

### L1.1: Test the AI Solution (3 min)

```bash
# Run the AI command on the test data
grep -E "^[a-zA-Z0-9]+@[a-zA-Z]+\.[a-zA-Z]+$" test_emails.txt
```

Questions:
1. What valid emails are OMITTED?
2. What invalid emails are ACCEPTED?

<details>
<summary>ğŸ“ Answers</summary>

OMITTED (false negatives):
- `john.doe@example.com` - has dot in local part
- `user@domain.co.uk` - has two dots in domain
- `alice_wonder@gmail.com` - has `_`
- `user.name+tag@domain.org` - has dot and plus

CORRECTLY ACCEPTED:
- `simple@test.io`
- `123@numbers.com` (partially - depends on interpretation)

Major problems with the AI regex:
- Does not accept `.` in the local part
- Does not accept `_` or `+`
- Does not accept subdomains (domain.co.uk)
</details>

### L1.2: Improve the Solution (5 min)

Rewrite the regex to correctly accept more email formats:

```bash
# Your improved solution:

```

<details>
<summary>âœ… Improved Solution</summary>

```bash
# Improved version
grep -E "^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$" test_emails.txt
```

Explanation of improvements:
- `[a-zA-Z0-9._%+-]+` - accepts dots, `_`, percent, plus, minus in local part
- `[a-zA-Z0-9.-]+` - accepts dots and minuses in domain (for subdomains)
- `[a-zA-Z]{2,}` - TLD of minimum 2 characters
</details>

### L1.3: Reflection (2 min)

Why did the LLM make mistakes?

<details>
<summary>ğŸ’¡ Analysis</summary>

LLMs tend to generate "simple" solutions that work for base cases but do not cover edge cases. The reasons:
1. The prompt did not specify detailed requirements
2. The LLM preferred simplicity
3. It did not test on diverse data

Lesson: Always test AI output on varied data!
</details>

---

# EXERCISE 2: SED TRANSFORMATION

## Context
A student asked: "Use sed to transform a config file from key=value format to JSON format"

## LLM Output (Simulated)

```bash
# Generated by AI:
sed 's/\(.*\)=\(.*\)/  "\1": "\2",/' config.txt
```

## Test Data

```bash
cat > test_config.txt << 'EOF'
# Database configuration
db.host=localhost
db.port=5432

# App settings
app.name=MyApp
app.debug=true
app.timeout=30
EOF
```

## Tasks

### L2.1: Identify Problems (3 min)

Run and observe the output:

```bash
sed 's/\(.*\)=\(.*\)/  "\1": "\2",/' test_config.txt
```

What problems do you observe?

<details>
<summary>ğŸ“ Identified Problems</summary>

1. Comments are processed - lines with # generate invalid output
2. Empty lines - generate lines with only `,`
3. Last line - has an extra comma (invalid JSON)
4. Missing JSON structure - does not have `{` and `}`
5. Numeric/boolean values - are treated as strings
</details>

### L2.2: Correct the Solution (7 min)

Create a complete solution that:
- Ignores comments and empty lines
- Generates valid JSON
- Handles the last comma

```bash
# Your solution:

```

<details>
<summary>âœ… Correct Solution</summary>

```bash
echo "{"
sed '/^#/d; /^$/d' test_config.txt | \
sed 's/\(.*\)=\(.*\)/  "\1": "\2",/' | \
sed '$ s/,$//'
echo "}"
```

Or more elegant with awk:

```bash
awk -F'=' '
BEGIN { print "{" }
/^#/ || /^$/ { next }
{ 
    if (NR > 1 && prev) print prev ","
    prev = sprintf("  \"%s\": \"%s\"", $1, $2)
}
END { 
    if (prev) print prev
    print "}"
}' test_config.txt
```
</details>

### L2.3: Prompt Engineering (2 min)

Rewrite the prompt to obtain a better solution from the LLM:

<details>
<summary>ğŸ’¡ Improved Prompt</summary>

```
Generate a sed or awk command that transforms a configuration file 
(key=value format) into valid JSON. Requirements:
1. Ignore lines starting with # (comments)
2. Ignore empty lines
3. The output must be valid JSON (no comma after the last pair)
4. Structure: { "key1": "value1", "key2": "value2" }
5. Use only standard Unix utilities (sed, awk, etc.)

Example input:
# comment
key1=value1
key2=value2

Example output:
{
  "key1": "value1",
  "key2": "value2"
}
```
</details>

---

# EXERCISE 3: AWK AGGREGATION

## Context
A student asked: "Write an awk command that calculates statistics from a sales CSV"

## LLM Output (Simulated)

```bash
# Generated by AI:
awk -F',' '{sum+=$3} END{print "Total: " sum}' sales.csv
```

## Test Data

```bash
cat > test_sales.csv << 'EOF'
Date,Product,Quantity,Price
2025-01-01,Widget,10,25.50
2025-01-01,Gadget,5,45.00
2025-01-02,Widget,8,25.50
2025-01-02,Gadget,12,45.00
2025-01-03,Widget,15,25.50
EOF
```

## Tasks

### L3.1: Evaluate Correctness (3 min)

```bash
awk -F',' '{sum+=$3} END{print "Total: " sum}' test_sales.csv
```

What problems does this solution have?

<details>
<summary>ğŸ“ Problems</summary>

1. Includes the header in calculation (Quantity is treated as 0, but it is not clean)
2. Calculates only the sum of quantities - perhaps the user wanted revenue
3. Does not validate data - what happens with non-numeric values?
4. Minimal output - just a number, without context
</details>

### L3.2: Unclear Requirements (2 min)

What statistics would actually be useful for sales data?

Your list:
1. 
2. 
3. 
4. 
5. 

<details>
<summary>ğŸ’¡ Useful Statistics</summary>

1. Total revenue (Quantity Ã— Price)
2. Total quantity sold
3. Product with most sales
4. Sales per day
5. Average revenue per transaction
6. Most profitable product
</details>

### L3.3: Complete Solution (7 min)

Create a complete sales report:

```bash
# Your solution:

```

<details>
<summary>âœ… Complete Solution</summary>

```bash
awk -F',' '
NR == 1 { next }  # Skip header
{
    qty += $3
    revenue += $3 * $4
    product_qty[$2] += $3
    product_rev[$2] += $3 * $4
    daily[$1] += $3 * $4
    count++
}
END {
    print "=== SALES REPORT ==="
    print ""
    print "Overall Statistics:"
    printf "  Total Transactions: %d\n", count
    printf "  Total Quantity: %d units\n", qty
    printf "  Total Revenue: $%.2f\n", revenue
    printf "  Avg per Transaction: $%.2f\n", revenue/count
    print ""
    print "By Product:"
    for (p in product_qty)
        printf "  %s: %d units, $%.2f\n", p, product_qty[p], product_rev[p]
    print ""
    print "By Day:"
    for (d in daily)
        printf "  %s: $%.2f\n", d, daily[d]
}' test_sales.csv
```
</details>

---

# EXERCISE 4: PIPELINE DEBUGGING

## Context
A student generated a pipeline with AI for log analysis but it does not work.

## LLM Output (With Errors)

```bash
# "Find top 10 IPs with 404 errors from access.log"
cat access.log | grep 404 | cut -d' ' -f1 | sort | unique -c | sort -n | head
```

## Tasks

### L4.1: Find All Errors (5 min)

Run the command and identify ALL problems:

```bash
cat access.log | grep 404 | cut -d' ' -f1 | sort | unique -c | sort -n | head
```

Errors found:
1. 
2. 
3. 
4. 
5. 

<details>
<summary>ğŸ“ Error List</summary>

1. `UUOC` - Useless Use of Cat (`cat | grep` â†’ `grep file`)
2. `unique` - Does not exist! The correct command is `uniq`
3. `grep 404` - May match IPs that contain 404
4. `sort -n` - Sorts ascending, but we want descending for "top"
5. `head` - OK, but without a number it takes 10 (OK for "top 10")
6. Wrong order - `uniq` must be AFTER `sort`
</details>

### L4.2: Correct the Pipeline (3 min)

```bash
# Corrected pipeline:

```

<details>
<summary>âœ… Correct Solution</summary>

```bash
grep ' 404 ' access.log | awk '{print $1}' | sort | uniq -c | sort -rn | head -10
```

Or:

```bash
awk '/ 404 / {print $1}' access.log | sort | uniq -c | sort -rn | head -10
```
</details>

---

# EXERCISE 5: PROMPT VS OUTPUT

## Context
Three students asked the LLM the same task with different prompts. Evaluate the results.

## Task
"Extract all URLs from an HTML file"

### Prompt A (Vague)
"regex for urls"

Output A:
```bash
grep 'http' file.html
```

### Prompt B (Specific)
"Write a grep command to extract all URLs (http and https) from an HTML file"

Output B:
```bash
grep -oE 'https?://[^"]+' file.html
```

### Prompt C (Detailed)
```
Write a grep command to extract all URLs from an HTML file.
Requirements:
- Match both http and https
- Extract only the URL, not surrounding text
- Handle URLs in href and src attributes
- Avoid matching partial URLs or false positives
Example input: <a href="https://example.com/page">Link</a>
Expected output: https://example.com/page
```

Output C:
```bash
grep -oE '(href|src)="https?://[^"]*"' file.html | grep -oE 'https?://[^"]*'
```

## Tasks

### L5.1: Evaluate Each (5 min)

| Output | Works? | Problems | Score (1-10) |
|--------|--------|----------|--------------|
| A | | | |
| B | | | |
| C | | | |

<details>
<summary>ğŸ“ Evaluation</summary>

| Output | Works? | Problems | Score |
|--------|--------|----------|-------|
| A | Partially | Does not extract, only displays lines; catches text with "http" too | 2/10 |
| B | Yes | May include unwanted characters; does not filter by context | 6/10 |
| C | Yes | Good, but excludes URLs from JavaScript, inline CSS | 8/10 |
</details>

### L5.2: Perfect Prompt (3 min)

Write the ideal prompt for this task:

```
[Your prompt here]
```

<details>
<summary>ğŸ’¡ Exemplary Prompt</summary>

```
Create a bash one-liner using grep or sed to extract all valid URLs from an HTML file.

Technical requirements:
1. Match http:// and https:// protocols
2. Extract ONLY the URL (use -o flag or equivalent)
3. Handle URLs in:
   - href attributes: href="https://..."
   - src attributes: src="https://..."
   - Plain text URLs
4. Stop URL extraction at first whitespace, quote, or >
5. Output one URL per line
6. Eliminate duplicates

Input example:
<html>
<a href="https://example.com/page">Link</a>
<img src="https://cdn.example.com/image.png">
Visit https://another.com for more info.
</html>

Expected output:
https://another.com
https://cdn.example.com/image.png
https://example.com/page

Show the command and explain each part.
```
</details>

---

# EXERCISE 6: COMPLETE EVALUATION

## Final Context
You receive this script generated by AI for "processing a CSV with student data".

```bash
#!/bin/bash
# Student grades processor (AI Generated)

cat students.csv | grep -v "^Name" | awk -F',' '{
    sum += $3
    if ($3 > 90) print $1 " - Excellent"
    if ($3 > 70) print $1 " - Good"  
    if ($3 > 50) print $1 " - Pass"
    else print $1 " - Fail"
} END {
    print "Average: " sum/NR
}'
```

## Test Data

```bash
cat > students.csv << 'EOF'
Name,ID,Grade
Alice,101,95
Bob,102,72
Carol,103,45
David,104,88
Eve,105,65
EOF
```

## Final Tasks

### L6.1: Complete Code Review (5 min)

Find ALL problems (minimum 5):

1. 
2. 
3. 
4. 
5. 
6. 

<details>
<summary>ğŸ“ All Problems</summary>

1. UUOC - `cat file | grep` inefficient
2. Wrong logic - the ifs are not else-if, Alice appears 3 times!
3. Header processing - `grep -v "^Name"` works, but is fragile
4. NR in END - NR includes all lines, not just those processed
5. No validation - what if Grade is not a number?
6. Shebang - OK, but missing `set -euo pipefail`
7. Not portable - assumes GNU awk
</details>

### L6.2: Rewrite Correctly (10 min)

```bash
#!/bin/bash
# Your correct version:

```

<details>
<summary>âœ… Correct Solution</summary>

```bash
#!/bin/bash
set -euo pipefail

awk -F',' '
NR == 1 { next }  # Skip header
{
    name = $1
    grade = $3
    sum += grade
    count++
    
    if (grade > 90) status = "Excellent"
    else if (grade > 70) status = "Good"
    else if (grade > 50) status = "Pass"
    else status = "Fail"
    
    printf "%s (ID: %s) - %d - %s\n", name, $2, grade, status
}
END {
    if (count > 0)
        printf "\nAverage Grade: %.2f\n", sum/count
    else
        print "No students found"
}' students.csv
```
</details>

---

## LLM-Aware Evaluation Rubric

| Criterion | Points | Description |
|-----------|--------|-------------|
| Error identification | 30% | Finding problems in AI output |
| Correction | 30% | Fixing identified errors |
| Improvement | 20% | Optimisation beyond correction |
| Prompt engineering | 10% | Reformulating requirements |
| Explanation | 10% | Understanding the reasons for errors |

---

## Takeaways

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ’¡ KEY LESSONS                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  1. LLMs generate PLAUSIBLE code, not necessarily CORRECT code         â”‚
â”‚                                                                         â”‚
â”‚  2. ALWAYS test on diverse data, including edge cases                  â”‚
â”‚                                                                         â”‚
â”‚  3. A better prompt = a better output                                  â”‚
â”‚                                                                         â”‚
â”‚  4. Understanding the concepts is essential for evaluation             â”‚
â”‚                                                                         â”‚
â”‚  5. LLM = assistant, not replacement for critical thinking             â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

*LLM-Aware Exercises for Operating Systems Seminar 4 | ASE Bucharest - CSIE*
